# -*- coding: utf-8 -*-
"""IE451_Assignment2_Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U7jO_HMe9kfX9jGjNmyPUYdoN0iQ-nKy
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.cluster import AgglomerativeClustering
from scipy.spatial import distance
from sklearn_extra.cluster import KMedoids
from scipy.cluster import hierarchy
from sklearn.cluster import DBSCAN

# Transform the excel file into a CSV file for simplicity

df = pd.read_csv("Assignment2_Q3.csv")
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)
df

"""## **Data Preparation**"""

# StandardScaler function implements standardization on the data as a preprocessing measure

scaler = StandardScaler()
df[:] = scaler.fit_transform(df[:])
df.drop_duplicates(inplace=True)
df
#Standardized version of features

"""## **K-Means Clustering**"""

# Function for determining optimal k number of clusters by plotting an Elbow Plot

def optimize_k_means(data, max_k):
  means = []
  inertias = []

  for k in range(1, max_k):
    kmeans = KMeans(n_clusters = k)
    kmeans.fit(data)
    means.append(k)
    inertias.append(kmeans.inertia_)

  fig = plt.subplots(figsize=(10,5))  
  plt.plot(means, inertias, "o-")
  plt.title("Elbow Plot")
  plt.xlabel("Number of Clusters")
  plt.ylabel("Inertia")
  #plt.grid(True)
  plt.show()

optimize_k_means(df[["Feature 1", "Feature 2", "Feature 3", "Feature 4"]], 20)

#Based on the elbow plot, the optimal k number of clusters is 5

# Apply K-Means Clustering for k in range(3,13)
df_kmeans = df.copy()
inertias = []
cluster_centers = []
for k in range(3,13):
  kmeans = KMeans(n_clusters=k)
  kmeans.fit(df_kmeans[:])
  df_kmeans[f"KMeans_{k}"] = kmeans.labels_
  
df_kmeans

"""## **K-Medians Clustering**"""

df_kmedians = df.copy()

# Get random values for centroids between a feature's min and max values

f1_min = df["Feature 1"].min()
f1_max = df["Feature 1"].max()

f2_min = df["Feature 2"].min()
f2_max = df["Feature 2"].max()

f3_min = df["Feature 3"].min()
f3_max = df["Feature 3"].max()

f4_min = df["Feature 4"].min()
f4_max = df["Feature 4"].max()

f1_centroid = np.random.uniform(f1_min, f1_max, 12)
f2_centroid = np.random.uniform(f2_min, f2_max, 12)
f3_centroid = np.random.uniform(f3_min, f3_max, 12)
f4_centroid = np.random.uniform(f4_min, f4_max, 12)

coordinates = np.array([f1_centroid, f2_centroid, f3_centroid, f4_centroid])
initial_centroids = coordinates.transpose()
#print(f"Coordinate List: {coordinates}\n")
print(f"Initial Centroids List: {initial_centroids}\n")  

for k in range(3,13):
  print(f"For k = {k}:\n")
  condition = True
  n = 1
  centroids = initial_centroids.copy()
  clusters = {}
  for i in range(1,k+1):
    clusters[f"Cluster{i}"] = [] 
  while condition:
    #print(f"Iteration {n}:\n")
    centroid_holder = centroids.copy()
    # Calculate the distances between each centroid and a 4-D point in df
    for i in range(df_kmedians.shape[0]):
      row = np.array(df_kmedians.iloc[i, :])
      distances = []
      for j in range(k):
        dst = distance.euclidean(row, centroids[j])
        distances.append(dst)
  
      closest_cluster = np.argmin(distances)
      clusters[f"Cluster{closest_cluster+1}"].append(row)
      
    x = []
    y = []
    z = []
    t = []
    c = 0
    for i in clusters:
      for j in clusters[i]:
        x.append(j[0])
        y.append(j[1])
        z.append(j[2])
        t.append(j[3])
      if len(x) != 0:  
        #print(np.median(x), np.median(y), np.median(z), np.median(t))
        centroids[c] = [np.median(x), np.median(y), np.median(z), np.median(t)]
      c += 1
    
    #print(f"Updated centroids:\n{centroid_holder}")
    n += 1  
    same = True 
    for l in range(len(centroids)):
      for m in range(len(centroids[0])):
        #print(f"{centroids[l][m]}, {centroid_holder[l][m]}")
        if centroids[l][m] != centroid_holder[l][m]:
          same = False
    if same:
      condition = False
  print(clusters)  
  print("\n")

"""## **K-Medoids Clustering**"""

df_kmedoids = df.copy()
inertias = []
cluster_centers = []
for k in range(3,13):
  kmedoids = KMedoids(n_clusters=k, random_state=0)
  kmedoids.fit(df_kmedoids[:])
  df_kmedoids[f"KMedoids_{k}"] = kmedoids.labels_
  inertias.append(kmedoids.inertia_)
  cluster_centers.append(kmedoids.cluster_centers_)
df_kmedoids

"""## **Agglomerative Hierarchical Clustering**"""

df_agglomerative = df.copy()

clusters = hierarchy.linkage(df_agglomerative, method="ward")
plt.figure(figsize=(8, 6))
dendrogram = hierarchy.dendrogram(clusters)
# Plotting a horizontal line based on the first biggest distance between clusters 
plt.axhline(150, color='red', linestyle='--'); 
# Plotting a horizontal line based on the second biggest distance between clusters 
plt.axhline(100, color='crimson');

inertias = []
cluster_centers = []
for k in range(3,13):
  agglomerative = AgglomerativeClustering(n_clusters=k, linkage="ward")
  agglomerative.fit(df_agglomerative[:])
  df_agglomerative[f"Cluster{k}"] = agglomerative.labels_
  inertias.append(kmedoids.inertia_)
  cluster_centers.append(kmedoids.cluster_centers_)
df_agglomerative

"""## **DBSCAN Clustering**"""

df_dbscan = df.copy()
dbscan = DBSCAN(eps=0.5, min_samples=7)
dbscan.fit(df_dbscan[:])
df_dbscan[f"Cluster"] = dbscan.labels_
df_dbscan

""" Expectation Maximization"""
#!pip install pyclustering
from pyclustering.cluster.ema import ema

data = df.to_numpy(dtype = float, copy=False)

f1 = data[:,0]
f2 = data[:,1]
f3 = data[:,2]
f4 = data[:,3]

data = list(zip(f1,f2,f3,f4))

for i in range(3,13):
  ema_ins = ema(data, i )
  ema_ins.process()
